#!/usr/bin/env python3
"""
ä¾èµ–å…³ç³»åˆ†æè„šæœ¬
ç”¨äºåˆ†æä»£ç åº“ä¸­çš„æ¨¡å—/æ–‡ä»¶ä¾èµ–å…³ç³»

ä½¿ç”¨æ–¹å¼:
    python analyze_dependencies.py python  # åˆ†æ Python é¡¹ç›®
    python analyze_dependencies.py js      # åˆ†æ JavaScript/TypeScript é¡¹ç›®
    python analyze_dependencies.py go      # åˆ†æ Go é¡¹ç›®
"""

import ast
import os
import re
import sys
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set, Tuple
import json


class DependencyAnalyzer:
    """åŸºç±»åˆ†æå™¨"""

    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.dependencies = defaultdict(set)
        self.reverse_dependencies = defaultdict(set)

    def analyze(self) -> Dict:
        """æ‰§è¡Œåˆ†æ"""
        raise NotImplementedError

    def get_circular_dependencies(self) -> List[List[str]]:
        """æ£€æµ‹å¾ªç¯ä¾èµ–"""
        visited = set()
        path = []
        cycles = []

        def dfs(node, start_node):
            if node in path:
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                cycles.append(cycle)
                return True

            if node in visited:
                return False

            visited.add(node)
            path.append(node)

            for neighbor in self.dependencies[node]:
                if dfs(neighbor, start_node):
                    return True

            path.pop()
            return False

        for node in list(self.dependencies.keys()):
            if node not in visited:
                dfs(node, node)

        return cycles

    def get_most_dependent_on(self, top_n: int = 5) -> List[Tuple[str, int]]:
        """è·å–è¢«ä¾èµ–æœ€å¤šçš„æ¨¡å—"""
        counts = [(node, len(deps)) for node, deps in self.dependencies.items()]
        return sorted(counts, key=lambda x: x[1], reverse=True)[:top_n]

    def get_most_dependent_by(self, top_n: int = 5) -> List[Tuple[str, int]]:
        """è·å–ä¾èµ–å…¶ä»–æ¨¡å—æœ€å¤šçš„æ¨¡å—"""
        counts = [(node, len(self.dependencies[node]))
                  for node in self.dependencies]
        return sorted(counts, key=lambda x: x[1], reverse=True)[:top_n]

    def generate_mermaid_graph(self, max_nodes: int = 20) -> str:
        """ç”Ÿæˆ Mermaid ä¾èµ–å›¾"""
        all_nodes = list(self.dependencies.keys())
        if len(all_nodes) > max_nodes:
            # åªæ˜¾ç¤ºæ ¸å¿ƒèŠ‚ç‚¹
            node_scores = {}
            for node in all_nodes:
                # è®¡ç®—èŠ‚ç‚¹é‡è¦æ€§ï¼ˆè¢«ä¾èµ– + ä¾èµ–å…¶ä»–ï¼‰
                score = len(self.reverse_dependencies[node]) + \
                        len(self.dependencies[node])
                node_scores[node] = score

            # é€‰æ‹©æœ€é‡è¦èŠ‚ç‚¹
            core_nodes = sorted(node_scores.items(),
                               key=lambda x: x[1],
                               reverse=True)[:max_nodes]
            core_nodes = [node for node, _ in core_nodes]
        else:
            core_nodes = all_nodes

        lines = []
        lines.append("graph TD")
        lines.append("")

        added_edges = set()
        for source in core_nodes:
            if source not in self.dependencies:
                continue

            for target in list(self.dependencies[source]):
                if target not in core_nodes:
                    continue

                edge = f"    {source} --> {target}"
                if edge not in added_edges:
                    lines.append(edge)
                    added_edges.add(edge)

        return "\n".join(lines)

    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("# ä¾èµ–å…³ç³»åˆ†ææŠ¥å‘Š")
        report.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        total_files = len(self.dependencies)
        total_deps = sum(len(deps) for deps in self.dependencies.values())

        report.append(f"- åˆ†ææ–‡ä»¶æ•°: {total_files}")
        report.append(f"- æ€»ä¾èµ–æ•°: {total_deps}")
        report.append(f"- å¹³å‡ä¾èµ–æ•°: {total_deps / max(total_files, 1):.2f}")
        report.append("")

        # å¾ªç¯ä¾èµ–
        cycles = self.get_circular_dependencies()
        report.append(f"## å¾ªç¯ä¾èµ–")
        if cycles:
            report.append(f"- **å‘ç° {len(cycles)} ä¸ªå¾ªç¯ä¾èµ–** âš ï¸")
            for i, cycle in enumerate(cycles, 1):
                report.append(f"\n### å¾ªç¯ {i}")
                for j in range(len(cycle) - 1):
                    report.append(f"- {cycle[j]} â†’ {cycle[j + 1]}")
        else:
            report.append("- æ²¡æœ‰å‘ç°å¾ªç¯ä¾èµ– âœ“")
        report.append("")

        # è¢«ä¾èµ–æœ€å¤šçš„æ¨¡å—
        report.append("## è¢«ä¾èµ–æœ€å¤šçš„æ¨¡å—ï¼ˆæ ¸å¿ƒæ¨¡å—ï¼‰")
        for module, count in self.get_most_dependent_on():
            report.append(f"- `{module}` - è¢« {count} ä¸ªæ¨¡å—ä¾èµ–")
        report.append("")

        # ä¾èµ–å…¶ä»–æ¨¡å—æœ€å¤šçš„æ¨¡å—
        report.append("## ä¾èµ–æœ€å¤šçš„æ¨¡å—ï¼ˆå¤æ‚æ¨¡å—ï¼‰")
        for module, count in self.get_most_dependent_by():
            report.append(f"- `{module}` - ä¾èµ– {count} ä¸ªæ¨¡å—")
        report.append("")

        # æ¶æ„å»ºè®®
        report.append("## æ¶æ„å»ºè®®")
        if cycles:
            report.append("\n### å¾ªç¯ä¾èµ–é—®é¢˜")
            report.append("- è€ƒè™‘æå–å…¬å…±é€»è¾‘åˆ°ç¬¬ä¸‰æ–¹æ¨¡å—")
            report.append("- åº”ç”¨ä¾èµ–å€’ç½®åŸåˆ™ï¼ˆä¾èµ–æŠ½è±¡è€Œéå…·ä½“å®ç°ï¼‰")
            report.append("- ä½¿ç”¨ä¾èµ–æ³¨å…¥å®¹å™¨ç®¡ç†ä¾èµ–\n")

        # é«˜ä¾èµ–æ¨¡å—å»ºè®®
        high_dependents = self.get_most_dependent_by(3)
        if high_dependents and high_dependents[0][1] > 10:
            report.append("\n### é«˜åº¦è€¦åˆæ¨¡å—")
            report.append(f"- `{high_dependents[0][0]}` ä¾èµ–äº† {high_dependents[0][1]} ä¸ªæ¨¡å—")
            report.append("- è€ƒè™‘æ¨¡å—æ‹†åˆ†ï¼Œé™ä½è€¦åˆåº¦")
            report.append("- æ£€æŸ¥æ˜¯å¦éµå¾ªå•ä¸€èŒè´£åŸåˆ™\n")

        report.append("## ä¾èµ–å…³ç³»å›¾")
        report.append("")
        report.append("\n```mermaid")
        report.append(self.generate_mermaid_graph())
        report.append("```\n")

        return "\n".join(report)


class PythonDependencyAnalyzer(DependencyAnalyzer):
    """Python ä¾èµ–åˆ†æå™¨"""

    def __init__(self, project_path: str):
        super().__init__(project_path)
        self.packages = set()

    def _extract_imports_from_file(self, file_path: Path) -> Set[str]:
        """ä» Python æ–‡ä»¶æå–å¯¼å…¥"""
        imports = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content, filename=str(file_path))

            for node in ast.walk(tree):
                # import module
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        module_name = alias.name.split('.')[0]
                        if self._is_internal_module(module_name, file_path):
                            imports.add(module_name)

                # from module import something
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        module_name = node.module.split('.')[0]
                        if self._is_internal_module(module_name, file_path):
                            imports.add(module_name)

        except SyntaxError as e:
            print(f"è¯­æ³•é”™è¯¯è§£æ {file_path}: {e}")
        except Exception as e:
            print(f"é”™è¯¯è§£æ {file_path}: {e}")

        return imports

    def _is_internal_module(self, module_name: str, current_file: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨æ¨¡å—"""
        # æ’é™¤æ ‡å‡†åº“å’Œç¬¬ä¸‰æ–¹åº“
        std_libs = {
            'os', 'sys', 're', 'json', 'datetime', 'typing', 'collections',
            'pathlib', 'ast', 'abc', 'uuid', 'hashlib', 'base64', 'hmac',
            'logging', 'io', 'functools', 'itertools', 'copy', 'pickle',
            'threading', 'multiprocessing', 'asyncio', 'subprocess',
            'email', 'http', 'urllib', 'socket', 'ssl', 'mimetypes',
            'inspect', 'textwrap', 'string', 'random', 'math', 'csv',
            'html', 'xml', 'zipfile', 'tarfile', 'sqlite3', 'decimal'
        }

        third_party_libs = {
            'fastapi', 'flask', 'django', 'sqlalchemy', 'alembic',
            'pytest', 'requests', 'httpx', 'pydantic', 'jinja2',
            'redis', 'celery', 'prometheus_client', 'aioredis',
            'psycopg2', 'mysql', 'asyncpg', 'motor', 'pymongo',
            'numpy', 'pandas', 'matplotlib', 'seaborn',
            'jwt', 'cryptography', 'bcrypt', 'passlib',
            'sentry_sdk', 'structlog', 'colorlog', 'uvicorn',
            'aiofiles', 'pillow', 'opencv', 'scipy', 'sklearn'
        }

        if module_name in std_libs or module_name in third_party_libs:
            return False

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„ç›®å½•æˆ–æ–‡ä»¶
        possible_paths = [
            self.project_path / f"{module_name.replace('.', '/')}.py",
            self.project_path / module_name.replace('.', '/') / '__init__.py',
        ]

        return any(p.exists() for p in possible_paths)

    def _module_path_to_name(self, file_path: Path) -> str:
        """å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºæ¨¡å—å"""
        try:
            rel_path = file_path.relative_to(self.project_path)
            if rel_path.name == '__init__.py':
                return str(rel_path.parent).replace('/', '.')
            else:
                return str(rel_path.with_suffix('')).replace('/', '.')
        except ValueError:
            return str(file_path).replace('/', '.')

    def analyze(self) -> Dict:
        """åˆ†æ Python é¡¹ç›®ä¾èµ–"""
        print("ğŸ” åˆ†æ Python é¡¹ç›®ä¾èµ–å…³ç³»...")

        # æŸ¥æ‰¾æ‰€æœ‰ Python æ–‡ä»¶
        python_files = list(self.project_path.rglob("*.py"))
        print(f"  æ‰¾åˆ° {len(python_files)} ä¸ª Python æ–‡ä»¶")

        # æå–æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥
        for file_path in python_files:
            module_name = self._module_path_to_name(file_path)
            imports = self._extract_imports_from_file(file_path)

            for imported in imports:
                self.dependencies[module_name].add(imported)
                self.reverse_dependencies[imported].add(module_name)

        # ç»Ÿè®¡
        self._analyze_third_party_packages()

        return {
            'dependencies': dict(self.dependencies),
            'reverse_dependencies': dict(self.reverse_dependencies),
            'packages': list(self.packages),
            'total_files': len(python_files),
        }

    def _analyze_third_party_packages(self):
        """åˆ†æç¬¬ä¸‰æ–¹åŒ…ä¾èµ–"""
        requirements_files = [
            self.project_path / 'requirements.txt',
            self.project_path / 'requirements' / 'base.txt',
            self.project_path / 'requirements' / 'dev.txt',
        ]

        for req_file in requirements_files:
            if req_file.exists():
                try:
                    with open(req_file, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith('#'):
                                # æå–åŒ…å
                                match = re.match(r'^([a-zA-Z0-9_-]+)', line)
                                if match:
                                    self.packages.add(match.group(1))
                except Exception as e:
                    print(f"è¯»å– {req_file} å¤±è´¥: {e}")


class JavaScriptDependencyAnalyzer(DependencyAnalyzer):
    """JavaScript/TypeScript ä¾èµ–åˆ†æå™¨"""

    def __init__(self, project_path: str):
        super().__init__(project_path)
        self.packages = set()

    def _extract_imports_from_file(self, file_path: Path) -> Set[str]:
        """ä» JS/TS æ–‡ä»¶æå–å¯¼å…¥"""
        imports = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ES6 import: import ... from '...'
            import_regex = r"import\s+.*?\s+from\s+['\"]([^'\"]+)['\"]"
            matches = re.findall(import_regex, content, re.MULTILINE)

            for module_path in matches:
                if self._is_internal_module(module_path, file_path):
                    imports.add(module_path)

            # CommonJS: require('...')
            require_regex = r"require\s*\(\s*['\"]([^'\"]+)['\"]\s*\)"
            matches = re.findall(require_regex, content, re.MULTILINE)

            for module_path in matches:
                if self._is_internal_module(module_path, file_path):
                    imports.add(module_path)

            # ES6 export from: export ... from '...'
            export_from_regex = r"export\s+.*?\s+from\s+['\"]([^'\"]+)['\"]"
            matches = re.findall(export_from_regex, content, re.MULTILINE)

            for module_path in matches:
                if self._is_internal_module(module_path, file_path):
                    imports.add(module_path)

        except Exception as e:
            print(f"é”™è¯¯è§£æ {file_path}: {e}")

        return imports

    def _is_internal_module(self, module_path: str, current_file: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨æ¨¡å—"""
        # æ’é™¤ node_modules å’Œå¤–éƒ¨åº“
        external_prefixes = [
            'react', 'react-dom', 'vue', 'angular',
            '@types/', 'typescript', '@typescript-eslint',
            'lodash', 'axios', 'moment', 'date-fns',
            'styled-components', '@emotion', '@mui',
            'react-router', 'react-query', 'swr',
            '@testing-library', 'jest', 'vitest',
            'vite', 'webpack', 'rollup', 'esbuild',
            'tailwindcss', 'postcss', 'sass', 'less',
            'zustand', 'redux', 'mobx', 'recoil',
            '@reduxjs', 'react-redux',
        ]

        for prefix in external_prefixes:
            if module_path.startswith(prefix):
                return False

        # ç›¸å¯¹è·¯å¾„å¯¼å…¥
        if module_path.startswith('.'):
            # è§£æç›¸å¯¹è·¯å¾„
            current_dir = current_file.parent
            target_path = (current_dir / module_path).resolve()

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
            if target_path.exists():
                return True
            if (target_path.with_suffix('.js')).exists():
                return True
            if (target_path.with_suffix('.ts')).exists():
                return True
            if (target_path.with_suffix('.tsx')).exists():
                return True
            if (target_path.with_suffix('.jsx')).exists():
                return True
            if (target_path / 'index.js').exists():
                return True
            if (target_path / 'index.ts').exists():
                return True

        return False

    def _module_path_to_name(self, file_path: Path) -> str:
        """å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºæ¨¡å—å"""
        try:
            rel_path = file_path.relative_to(self.project_path)
            return str(rel_path.with_suffix(''))
        except ValueError:
            return str(file_path)

    def analyze(self) -> Dict:
        """åˆ†æ JavaScript/TypeScript é¡¹ç›®ä¾èµ–"""
        print("ğŸ” åˆ†æ JavaScript/TypeScript é¡¹ç›®ä¾èµ–å…³ç³»...")

        # æŸ¥æ‰¾æ‰€æœ‰ JS/TS/JSX/TSX æ–‡ä»¶
        extensions = ['*.js', '*.ts', '*.jsx', '*.tsx']
        js_files = []
        for ext in extensions:
            js_files.extend(self.project_path.rglob(ext))

        # æ’é™¤ node_modules
        js_files = [f for f in js_files if 'node_modules' not in str(f)]

        print(f"  æ‰¾åˆ° {len(js_files)} ä¸ª JS/TS æ–‡ä»¶")

        # æå–æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥
        for file_path in js_files:
            module_name = self._module_path_to_name(file_path)
            imports = self._extract_imports_from_file(file_path)

            for imported in imports:
                self.dependencies[module_name].add(imported)
                self.reverse_dependencies[imported].add(module_name)

        # åˆ†æ package.json
        self._analyze_packages()

        return {
            'dependencies': dict(self.dependencies),
            'reverse_dependencies': dict(self.reverse_dependencies),
            'packages': list(self.packages),
            'total_files': len(js_files),
        }

    def _analyze_packages(self):
        """åˆ†æ package.json"""
        package_json = self.project_path / 'package.json'
        if package_json.exists():
            try:
                with open(package_json, 'r') as f:
                    data = json.load(f)

                deps = data.get('dependencies', {})
                dev_deps = data.get('devDependencies', {})

                self.packages.update(deps.keys())
                self.packages.update(dev_deps.keys())
            except Exception as e:
                print(f"è§£æ package.json å¤±è´¥: {e}")


class GoDependencyAnalyzer(DependencyAnalyzer):
    """Go ä¾èµ–åˆ†æå™¨"""

    def __init__(self, project_path: str):
        super().__init__(project_path)
        self.packages = set()

    def _extract_imports_from_file(self, file_path: Path) -> Set[str]:
        """ä» Go æ–‡ä»¶æå–å¯¼å…¥"""
        imports = set()

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # åŒ¹é… import è¯­å¥
            import_regex = r'import\s+\(\s*([^)]+)\s*\)'
            block_matches = re.findall(import_regex, content, re.DOTALL)

            for block in block_matches:
                for line in block.split('\n'):
                    line = line.strip()
                    if line and not line.startswith('//'):
                        # å¤„ç†å¸¦åˆ«åçš„å¯¼å…¥: alias "package"
                        match = re.match(r'.*"([^"]+)"', line)
                        if match:
                            package = match.group(1)
                            if self._is_internal_package(package, file_path):
                                imports.add(package)

            # å•è¡Œ import
            import_regex = r'import\s+(?:\w+\s+)?"([^"]+)"'
            matches = re.findall(import_regex, content)
            for package in matches:
                if self._is_internal_package(package, file_path):
                    imports.add(package)

        except Exception as e:
            print(f"é”™è¯¯è§£æ {file_path}: {e}")

        return imports

    def _is_internal_package(self, package_path: str, current_file: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨åŒ…"""
        # æ’é™¤æ ‡å‡†åº“å’Œå¤–éƒ¨åº“
        external_packages = {
            'fmt', 'os', 'io', 'net/http', 'encoding/json',
            'database/sql', 'time', 'strconv', 'strings',
            'sync', 'context', 'log', 'errors', 'flag',
            'reflect', 'regexp', 'sort', 'math', 'bytes',
            'bufio', 'crypto', 'encoding', 'path', 'runtime',
            'testing', 'github.com', 'golang.org',
            'google.golang.org', 'go.uber.org', 'gorm.io',
            'github.com/gin-gonic', 'github.com/gorilla',
        }

        # å¦‚æœæ˜¯ç›¸å¯¹å¯¼å…¥
        if package_path.startswith('.'):
            return True

        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨åŒ…
        internal_path = self.project_path / package_path
        if internal_path.exists():
            return True

        return False

    def _module_path_to_name(self, file_path: Path) -> str:
        """å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºåŒ…å"""
        try:
            rel_path = file_path.parent.relative_to(self.project_path)
            module_name = str(rel_path)
            if module_name == '.':
                return 'main'
            return module_name
        except ValueError:
            return str(file_path.parent)

    def analyze(self) -> Dict:
        """åˆ†æ Go é¡¹ç›®ä¾èµ–"""
        print("ğŸ” åˆ†æ Go é¡¹ç›®ä¾èµ–å…³ç³»...")

        # æŸ¥æ‰¾æ‰€æœ‰ .go æ–‡ä»¶ï¼ˆæ’é™¤ vendorï¼‰
        go_files = list(self.project_path.rglob("*.go"))
        go_files = [f for f in go_files if 'vendor' not in str(f)]

        print(f"  æ‰¾åˆ° {len(go_files)} ä¸ª Go æ–‡ä»¶")

        # æå–æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥
        for file_path in go_files:
            module_name = self._module_path_to_name(file_path)
            imports = self._extract_imports_from_file(file_path)

            for imported in imports:
                self.dependencies[module_name].add(imported)
                self.reverse_dependencies[imported].add(module_name)

        # åˆ†æ go.mod
        self._analyze_go_mod()

        return {
            'dependencies': dict(self.dependencies),
            'reverse_dependencies': dict(self.reverse_dependencies),
            'packages': list(self.packages),
            'total_files': len(go_files),
        }

    def _analyze_go_mod(self):
        """åˆ†æ go.mod"""
        go_mod = self.project_path / 'go.mod'
        if go_mod.exists():
            try:
                with open(go_mod, 'r') as f:
                    content = f.read()

                # æå–ä¾èµ–åŒ…
                for line in content.split('\n'):
                    line = line.strip()
                    if line and not line.startswith('module') and \
                       not line.startswith('go ') and not line.startswith('(') and \
                       not line.startswith(')') and not line.startswith('//'):
                        parts = line.split()
                        if parts:
                            self.packages.add(parts[0])
            except Exception as e:
                print(f"è§£æ go.mod å¤±è´¥: {e}")


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyze_dependencies.py <language>")
        print("è¯­è¨€é€‰é¡¹: python, js, go")
        sys.exit(1)

    language = sys.argv[1].lower()
    project_path = os.getcwd()

    # é€‰æ‹©åˆ†æå™¨
    if language == 'python':
        analyzer = PythonDependencyAnalyzer(project_path)
    elif language in ['js', 'javascript', 'typescript', 'ts']:
        analyzer = JavaScriptDependencyAnalyzer(project_path)
    elif language == 'go':
        analyzer = GoDependencyAnalyzer(project_path)
    else:
        print(f"ä¸æ”¯æŒçš„è¯­è¨€: {language}")
        print("æ”¯æŒçš„è¯­è¨€: python, js, typescript, go")
        sys.exit(1)

    # æ‰§è¡Œåˆ†æ
    results = analyzer.analyze()

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()
    print("\n" + "=" * 80)
    print("ä¾èµ–å…³ç³»åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print(report)

    # ä¿å­˜åˆ°æ–‡ä»¶
    report_file = Path('dependency_report.md')
    with open(report_file, 'w') as f:
        f.write(report)

    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    return results


if __name__ == '__main__':
    main()
